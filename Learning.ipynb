{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Robin Goh\n",
    "# This assignment is done by referencing to the book Make Your Own Neural Network by Tariq Rashid.\n",
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "\n",
    "# A neural network class that can create, train and query a 3-layer neural networks.\n",
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    # initialize the neural network\n",
    "    # need number of input, hidden and out layer nodes.\n",
    "    # also the learning rate\n",
    "    def __init__(self, inputNodes, hiddenNodes, outputNodes, learningRate):\n",
    "        self.inputNodes = inputNodes\n",
    "        self.hiddenNodes = hiddenNodes\n",
    "        self.outputNodes = outputNodes\n",
    "        self.learningRate = learningRate\n",
    "\n",
    "        # Most important part of the network is the link weights\n",
    "        # since they're used to calculate the forwarded signal and the backwarded error.\n",
    "        # Weights can be expressed in a matrix. So create:\n",
    "        # 1. a matrix for the weights of links between the input and hidden layers\n",
    "        #    with size hiddenNodes * inputNodes\n",
    "        # 2. a matrix for the weights of links between the hidden and output layers\n",
    "        #    with size outputNodes * hiddenNodes\n",
    "        # Initially, the values of the link weights should be small and random.\n",
    "        # Use numpy.random.rand(rows, cols) to generate an array between 0 and 1 randomly.\n",
    "        # The weights can be negative, so substract the above with 0.5 to get range -0.5 to 0.5\n",
    "        # weight matrices wih, who\n",
    "        # w_ij is the weight of the link from node i to node j in the next layer\n",
    "        self.wih = numpy.random.rand(self.hiddenNodes, self.inputNodes) - 0.5\n",
    "        self.who = numpy.random.rand(self.outputNodes, self.hiddenNodes) - 0.5\n",
    "        # To optimize, use numpy.random.normal() to sample a normal distribution\n",
    "        # params are the center of the distribution, standard deviation, and size of a numpy array\n",
    "        # self.wih = numpy.random.normal(0.0, pow(self.hiddenNodes, -0.5), (self.hiddenNodes, self.inputNodes))\n",
    "        # self.who = numpy.random.normal(0.0, pow(self.outputNodes, -0.5), (self.outputNodes, self.hiddenNodes))\n",
    "\n",
    "        # activation function is the sigmoid function\n",
    "        self.activationFunction = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "\n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # 1st part: working out the output of an input, just like in query()\n",
    "        # convert arguments from list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "\n",
    "        hiddenInputs = numpy.dot(self.wih, inputs)\n",
    "        hiddenOutputs = self.activationFunction(hiddenInputs)\n",
    "\n",
    "        finalInputs = numpy.dot(self.who, hiddenOutputs)\n",
    "        finalOutputs = self.activationFunction(finalInputs)\n",
    "\n",
    "        # 2nd part: taking the calculated output from the 1st part,\n",
    "        #           comparing it with the desired output,\n",
    "        #           and using the difference to update the network weights.\n",
    "        # error = target - actual\n",
    "        outputErrors = targets - finalOutputs\n",
    "        # error_hidden = transpose(weights_hidden_output) dot errors_output\n",
    "        # hidden layer error is the outputErrors, split by weights, recombined at hidden nodes\n",
    "        hiddenErrors = numpy.dot(self.who.T, outputErrors)\n",
    "        # to refine the weights at each layer,\n",
    "        # use outputErrors for the weights between the hidden and final layers\n",
    "        # use hiddenErrors for the weights between the input and hidden layers\n",
    "        # Expression for updating the weight of the link between a node j and node k in the next layer:\n",
    "        # delW_jk = alpha * E_k * sigmoid(O_k) * ( 1- sigmoid(O_k) ) dot transpose(O_j), alpha is the learning rate\n",
    "        # update the weights of the links between the hidden and output layers\n",
    "        self.who += self.learningRate \\\n",
    "                    * numpy.dot((outputErrors * finalOutputs * (1.0 - finalOutputs)), numpy.transpose(hiddenOutputs))\n",
    "        # update the weights of the links between the input and hidden layers\n",
    "        self.wih += self.learningRate \\\n",
    "                    * numpy.dot((hiddenErrors * hiddenOutputs * (1.0 - hiddenOutputs)), numpy.transpose(inputs))\n",
    "\n",
    "        pass\n",
    "\n",
    "    # query the nerural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array, since input is written inside square brackets, which will be a list\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        # signals into the hidden layer nodes = weights of the link between input_hidden layers dot input matrix\n",
    "        # calculate the signals into the hidden layer\n",
    "        hiddenInputs = numpy.dot(self.wih, inputs)\n",
    "        # to get the signals emerging from the hidden node, apply the sigmoid squashing function to each emergin signals\n",
    "        # O_hidden = sigmoid(X_hidden)\n",
    "        # calculate the signals emerging from the hidden layer\n",
    "        hiddenOutputs = self.activationFunction(hiddenInputs)\n",
    "        # calculate the signals into the final output layer\n",
    "        finalInputs = numpy.dot(self.who, hiddenOutputs)\n",
    "        # calculate the signals emerging from the final output layer\n",
    "        finalOutputs = self.activationFunction(finalInputs)\n",
    "        return finalOutputs\n",
    "\n",
    "    # define number of input, hidden and output nodes, and the learning rate\n",
    "    inputNodes = 784\n",
    "    hiddenNodes = 100\n",
    "    outputNodes = 10\n",
    "    learningRate = 0.3\n",
    "\n",
    "    # create an instance of the neural network\n",
    "    ann = neuralNetwork(inputNodes, hiddenNodes, outputNodes, learningRate)\n",
    "\n",
    "    def prepareData(self):\n",
    "        # Rescale input color values from [0, 255] to [0.01, 1.0]. 0.01 is chosen since zero valued inputs can\n",
    "        # kill weight updates. No need to choose 0.99 as the upper end of the input but should avoid in the output case.\n",
    "        scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "    def open(self):\n",
    "        data_file = open(\"/Users/robg/Downloads/mnist_train_100.csv\", 'r')\n",
    "        data_list = data_file.readlines()\n",
    "        data_file.close()\n",
    "\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
